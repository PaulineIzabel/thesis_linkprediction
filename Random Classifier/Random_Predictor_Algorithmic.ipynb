{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Predictor for algorithmic methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_directed(graph, actual_edges, multi = False):\n",
    "      \n",
    "    n = graph.number_of_nodes()\n",
    "    nodes = list(graph.nodes)\n",
    "    \n",
    "    data0_Y_train = []\n",
    "    data0_nodes_train = []\n",
    "    Y_train = []\n",
    "    Y_test, nodes_test = [],[]\n",
    "    \n",
    "    for i in range(n):\n",
    "        neighbors = [n for n in graph.neighbors(nodes[i])] # list of the neighbors of node i\n",
    "        for j in range(n):\n",
    "            if i != j :\n",
    "                \n",
    "                if nodes[j] in neighbors: \n",
    "\n",
    "                    # there is a link between the nodes in the graph\n",
    "                    # the training set is composed of all the present edges of the graph\n",
    "                    Y_train.append(1)\n",
    "                \n",
    "                if (multi==False and nodes[j] not in neighbors) or (multi==True): \n",
    "                    # there is no link between the nodes in the graph, if it is not a multigraph\n",
    "                    \n",
    "                    if [nodes[i],nodes[j]] not in actual_edges: \n",
    "                        # this is not one of the removed edges\n",
    "                        data0_nodes_train.append([nodes[i],nodes[j]])\n",
    "                        data0_Y_train.append(0)\n",
    "                    else: # the testing set is composed of all the present edges previously removed\n",
    "                        nodes_test.append([nodes[i],nodes[j]])\n",
    "                        Y_test.append(1)\n",
    "    \n",
    "    l = int(len(data0_Y_train)/5) # the number of absent edges in the graph to remove\n",
    "   \n",
    "    # We shuffle the data of absence of edges in the same way \n",
    "    data0 = list(zip(data0_nodes_train, data0_Y_train))\n",
    "    random.shuffle(data0)\n",
    "    data0_nodes_train, data0_Y_train = zip(*data0)\n",
    "    \n",
    "    # We randomly remove 1/5 of the absent edges of the graph\n",
    "    Y_train += data0_Y_train[l:]\n",
    "    \n",
    "    # We randomly add the 1/5 to the pairs of nodes to predict\n",
    "    Y_test += data0_Y_train[:l]\n",
    "    nodes_test += data0_nodes_train[:l]\n",
    "    \n",
    "    return Y_train, Y_test, nodes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_undirected(graph, actual_edges, multi = False):\n",
    "      \n",
    "    n = graph.number_of_nodes()\n",
    "    nodes = list(graph.nodes)\n",
    "    edges = list(graph.edges)\n",
    "    \n",
    "    data0_Y_train = []\n",
    "    data0_nodes_train = []\n",
    "    Y_train = []\n",
    "    Y_test, nodes_test = [],[]\n",
    "\n",
    "    for i in range(n):\n",
    "        neighbors = [n for n in graph.neighbors(nodes[i])] # list of the neighbors of node i\n",
    "        for j in range(i+1,n):\n",
    "            if i != j :\n",
    "                \n",
    "                if nodes[j] in neighbors: \n",
    "                    # there is a link between the nodes in the graph\n",
    "                    # the training set is composed of all the present edges of the graph\n",
    "                    Y_train.append(1)\n",
    "                \n",
    "                if (multi==False and nodes[j] not in neighbors) or (multi==True): \n",
    "                    # there is no link between the nodes in the graph, if it is not a multigraph\n",
    "                    \n",
    "                    # Notation: the nodes of minimum number first                             \n",
    "                    if [min(nodes[i],nodes[j]),max(nodes[i],nodes[j])] not in actual_edges: \n",
    "                        # this is not one of the removed edges\n",
    "                        data0_nodes_train.append([min(nodes[i],nodes[j]),max(nodes[i],nodes[j])])\n",
    "                        data0_Y_train.append(0)\n",
    "\n",
    "                    else: # the testing set is composed of all the present edges previously removed\n",
    "                        nodes_test.append([min(nodes[i],nodes[j]),max(nodes[i],nodes[j])])\n",
    "                        Y_test.append(1)      \n",
    "                \n",
    "\n",
    "    l = int(len(data0_Y_train)/5) # the number of absent edges in the graph to remove\n",
    "\n",
    "    # We shuffle the data of absence of edges in the same way \n",
    "    data0 = list(zip(data0_nodes_train, data0_Y_train))\n",
    "    random.shuffle(data0)\n",
    "    data0_nodes_train, data0_Y_train = zip(*data0)\n",
    "    \n",
    "    # We randomly remove 1/5 of the absent edges of the graph\n",
    "    Y_train += data0_Y_train[l:]\n",
    "    \n",
    "    # We randomly add the 1/5 to the pairs of nodes to predict\n",
    "    Y_test += data0_Y_train[:l]\n",
    "    nodes_test += data0_nodes_train[:l]\n",
    "    \n",
    "    return Y_train, Y_test, nodes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_prediction_undirected(graph, nodes_test, k, multi = False):\n",
    "    \n",
    "\n",
    "    n = graph.number_of_nodes()\n",
    "    nodes = list(graph.nodes)\n",
    "    links = []\n",
    "    random.shuffle(nodes) # so that the prediction is not defined by the order of the nodes\n",
    "    random.shuffle(nodes_test)\n",
    "\n",
    "    if multi==True:\n",
    "        while len(links) < k:\n",
    "            i = random.randint(0,n-1)\n",
    "            j = random.randint(0,n-1)\n",
    "            # if multigraph, we can predict another edge, where we already have one\n",
    "            # so we can predict any pair of nodes (but only once)\n",
    "            if [min(nodes[i],nodes[j]),max(nodes[i],nodes[j])] not in links: \n",
    "                # We don't want to predict the same edge twice\n",
    "                links.append([min(nodes[i],nodes[j]),max(nodes[i],nodes[j])])\n",
    "    else:\n",
    "        while len(links) < k:\n",
    "            # We don't want to predict edges already existing, if not multigraph\n",
    "            # so we randomly select pairs of the testing set\n",
    "            l = random.randint(0,len(nodes_test)-1)\n",
    "            if nodes_test[l] not in links: \n",
    "                # We don't want to predict the same edge twice\n",
    "                links.append(nodes_test[l])\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_prediction_directed(graph, nodes_test, k, multi = False):\n",
    "    \n",
    "\n",
    "    n = graph.number_of_nodes()\n",
    "    nodes = list(graph.nodes)\n",
    "    links = []\n",
    "    random.shuffle(nodes) # so that the prediction is not defined by the order of the nodes\n",
    "    random.shuffle(nodes_test)\n",
    "    \n",
    "    if multi==True:\n",
    "        while len(links) < k:\n",
    "            i = random.randint(0,n-1)\n",
    "            j = random.randint(0,n-1)\n",
    "            # if multigraph, we can predict another edge, where we already have one\n",
    "            # so we can predict any pair of nodes (but only once)\n",
    "            if [nodes[i],nodes[j]] not in links: \n",
    "                # We don't want to predict the same edge twice\n",
    "                links.append([nodes[i],nodes[j]])\n",
    "    else:\n",
    "        while len(links) < k:\n",
    "            # We don't want to predict edges already existing, if not multigraph\n",
    "            # so we randomly select pairs of the testing set\n",
    "            l = random.randint(0,len(nodes_test)-1)\n",
    "            if nodes_test[l] not in links: \n",
    "                # We don't want to predict the same edge twice\n",
    "                links.append(nodes_test[l])\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function giving MAP for random predictor\n",
    "\n",
    "def random_results(predictions, actual_edges, graph):\n",
    "    \n",
    "    n = graph.number_of_nodes()\n",
    "    nodes = list(graph.nodes)\n",
    "    n_edges = graph.number_of_edges()\n",
    "    test_size = len(actual_edges)\n",
    "    \n",
    "    precisions = []\n",
    "    MAP = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    for k in range(len(predictions)):\n",
    "            \n",
    "        if predictions[k] in actual_edges:\n",
    "            tp += 1\n",
    "            MAP += (tp /(tp + fp))   \n",
    "        else:\n",
    "            fp += 1\n",
    "                \n",
    "    if tp == 0:  # Not even one good prediction\n",
    "        return 0\n",
    "    \n",
    "    return(MAP/tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation results for random predictor\n",
    "\n",
    "def CV_random_results(list_graphs, list_targets, network_type='undirected', multi = False):\n",
    "    test_size = len(list_targets[0])\n",
    "    MAP = 0\n",
    "    \n",
    "    for part in range(5):\n",
    "        \n",
    "            if network_type == 'directed':\n",
    "                Y_train, Y_test, nodes_test = features_directed(list_graphs[part], list_targets[part], multi)\n",
    "            else:\n",
    "                Y_train, Y_test, nodes_test = features_undirected(list_graphs[part], list_targets[part], multi)\n",
    "                \n",
    "            for i in range(100):\n",
    "                \n",
    "                if network_type == 'directed':\n",
    "                    predictions = random_prediction_directed(list_graphs[part],nodes_test,test_size,multi)\n",
    "                else: predictions = random_prediction_undirected(list_graphs[part],nodes_test,test_size,multi)\n",
    "            \n",
    "                MAP_N = random_results(predictions,list_targets[part],list_graphs[part])\n",
    "                MAP = MAP+MAP_N\n",
    "  \n",
    "    return(MAP/500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First dataset: PROTEINS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of the dataset: PROTEINS\n",
    "# http://konect.uni-koblenz.de/networks/maayan-Stelzl \n",
    "\n",
    "PROT = []\n",
    "with open('out.maayan-Stelzl') as inputfile:\n",
    "    for line in inputfile:\n",
    "        PROT.append(line.strip().split(','))\n",
    "PROT = PROT[1:] # list of all the edges\n",
    "random.shuffle(PROT) # we randomly shuffle the edges\n",
    "\n",
    "# test size\n",
    "num_edges_PROT = len(PROT)\n",
    "num_vertices_PROT = 1706\n",
    "test_size_PROT = int(num_edges_PROT/5)\n",
    "\n",
    "# Contains the 5 parts forming the whole dataset\n",
    "parts_PROT = []\n",
    "\n",
    "start = 0\n",
    "end = test_size_PROT\n",
    "for part in range(5):  # We create the 5 parts\n",
    "    if end>num_edges_PROT:\n",
    "        parts_PROT.append(PROT[start:])\n",
    "    else:parts_PROT.append(PROT[start:end])\n",
    "    start = end\n",
    "    end = start + test_size_PROT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROT_G = nx.DiGraph()\n",
    "for edge in range(len(PROT)):\n",
    "    nodes = PROT[edge][0].split(' ')\n",
    "    PROT_G.add_edge(int(nodes[0]), int(nodes[1])) \n",
    "PROT_nodes = PROT_G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs contains the 5 different training networks \n",
    "# targets contains the target links corresponding\n",
    "\n",
    "PROT_graphs = []\n",
    "PROT_targets = []\n",
    "\n",
    "for i in range(5):     # i is the index of the folder we won't use\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(PROT_nodes)\n",
    "    target_links = [] \n",
    "    for j in range(5): # We use every other folder\n",
    "        data = parts_PROT[j]\n",
    "        if j!=i:        \n",
    "            for edge in range(len(data)):\n",
    "                nodes = data[edge][0].split(' ')\n",
    "                G.add_edge(int(nodes[0]), int(nodes[1])) \n",
    "                \n",
    "                \n",
    "        else:\n",
    "            for edge in range(len(data)):\n",
    "                nodes = data[edge][0].split(' ')\n",
    "                target_links.append([int(nodes[0]),int(nodes[1])])\n",
    "                \n",
    "                \n",
    "\n",
    "    PROT_graphs.append(G)\n",
    "    PROT_targets.append(target_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_R = CV_random_results(PROT_graphs,PROT_targets,'directed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006636022533431954"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second dataset: INFECTIOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of the dataset: INFECTIOUS\n",
    "# http://konect.uni-koblenz.de/networks/sociopatterns-infectious \n",
    "\n",
    "INF = []\n",
    "with open('sociopatterns-infectious\\out.sociopatterns-infectious') as inputfile:\n",
    "    for line in inputfile:\n",
    "        INF.append(line.strip().split(','))\n",
    "INF = INF[2:] # list of all the edges\n",
    "random.shuffle(INF) # we randomly shuffle the edges\n",
    "\n",
    "# test size\n",
    "num_edges_INF = len(INF)\n",
    "num_vertices_INF = 410\n",
    "test_size_INF = int(num_edges_INF/5)\n",
    "\n",
    "# Contains the 5 parts forming the whole dataset\n",
    "parts_INF = []\n",
    "\n",
    "start = 0\n",
    "end = test_size_INF\n",
    "for part in range(5):  # We create the 5 parts\n",
    "    if end>num_edges_INF:\n",
    "        parts_INF.append(INF[start:])\n",
    "    else:parts_INF.append(INF[start:end])\n",
    "    start = end\n",
    "    end = start + test_size_INF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INF_G = nx.MultiGraph()\n",
    "for edge in range(len(INF)):\n",
    "    nodes = INF[edge][0].split(' ')\n",
    "    INF_G.add_edge(int(nodes[0]), int(nodes[1])) \n",
    "INF_nodes = INF_G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs contains the 5 different training networks \n",
    "# targets contains the target links corresponding\n",
    "\n",
    "INF_graphs = []\n",
    "INF_targets = []\n",
    "\n",
    "for i in range(5):     # i is the index of the folder we won't use\n",
    "    G = nx.MultiGraph()\n",
    "    G.add_nodes_from(INF_nodes)\n",
    "    target_links = [] \n",
    "    for j in range(5): # We use every other folder\n",
    "        data = parts_INF[j]\n",
    "        if j!=i:        \n",
    "            for edge in range(len(data)):\n",
    "                nodes = data[edge][0].split(' ')\n",
    "                G.add_edge(int(nodes[0]), int(nodes[1])) \n",
    "                \n",
    "                \n",
    "        else:\n",
    "            for edge in range(len(data)):\n",
    "                nodes = data[edge][0].split(' ')\n",
    "                # For undirected network, we write the min node first\n",
    "                # We don't want duplicates because we cannot predict the number of edges to add\n",
    "                if [min(int(nodes[0]),int(nodes[1])),max(int(nodes[0]),int(nodes[1]))] not in target_links:\n",
    "                    target_links.append([min(int(nodes[0]),int(nodes[1])),max(int(nodes[0]),int(nodes[1]))])\n",
    "                \n",
    "                \n",
    "    INF_graphs.append(G)\n",
    "    INF_targets.append(target_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_INF_R = CV_random_results(INF_graphs,INF_targets,'undirected',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020540572978007626"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP_INF_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third dataset: ADOLESCENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of the dataset: ADOLESCENT\n",
    "# http://konect.uni-koblenz.de/networks/moreno_health\n",
    "\n",
    "ADO = []\n",
    "with open('moreno_health\\out.moreno_health_health') as inputfile:\n",
    "    for line in inputfile:\n",
    "        ADO.append(line.strip().split(','))\n",
    "ADO = ADO[2:] # list of all the edges\n",
    "random.shuffle(ADO) # we randomly shuffle the edges\n",
    "\n",
    "# test size\n",
    "num_edges_ADO = len(ADO)\n",
    "num_vertices_ADO = 2539\n",
    "test_size_ADO = int(num_edges_ADO/5)\n",
    "\n",
    "# Contains the 5 parts forming the whole dataset\n",
    "parts_ADO = []\n",
    "\n",
    "start = 0\n",
    "end = test_size_ADO\n",
    "for part in range(5):  # We create the 5 parts\n",
    "    if end>num_edges_ADO:\n",
    "        parts_ADO.append(ADO[start:])\n",
    "    else:parts_ADO.append(ADO[start:end])\n",
    "    start = end\n",
    "    end = start + test_size_ADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADO_G = nx.DiGraph()\n",
    "for edge in range(len(ADO)):\n",
    "    nodes = ADO[edge][0].split(' ')\n",
    "    ADO_G.add_edge(int(nodes[0]), int(nodes[1]), weight=float(nodes[2]))\n",
    "ADO_nodes = ADO_G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs contains the 5 different training networks \n",
    "# targets contains the target links corresponding\n",
    "\n",
    "ADO_graphs = []\n",
    "ADO_targets = []\n",
    "\n",
    "for i in range(5):     # i is the index of the folder we won't use\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(ADO_nodes)\n",
    "    target_links = [] \n",
    "    for j in range(5): # We use every other folder\n",
    "        data = parts_ADO[j]\n",
    "        if j!=i:        \n",
    "            for edge in range(len(data)):\n",
    "                nodes = data[edge][0].split(' ')\n",
    "                G.add_edge(int(nodes[0]), int(nodes[1]), weight=float(nodes[2])) \n",
    "                \n",
    "                \n",
    "        else:\n",
    "            for edge in range(len(data)):\n",
    "                nodes = data[edge][0].split(' ')\n",
    "                target_links.append([int(nodes[0]),int(nodes[1])])\n",
    "                \n",
    "                \n",
    "\n",
    "    ADO_graphs.append(G)\n",
    "    ADO_targets.append(target_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_ADO_R = CV_random_results(ADO_graphs,ADO_targets,'directed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004748975372132157"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP_ADO_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth dataset: MISERABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of the dataset: MISERABLES\n",
    "# http://konect.uni-koblenz.de/networks/moreno_lesmis\n",
    "\n",
    "MIS = []\n",
    "with open('moreno_lesmis\\out.moreno_lesmis_lesmis') as inputfile:\n",
    "    for line in inputfile:\n",
    "        MIS.append(line.strip().split(','))\n",
    "MIS = MIS[2:] # list of all the edges\n",
    "random.shuffle(MIS) # we randomly shuffle the edges\n",
    "\n",
    "# test size\n",
    "num_edges_MIS = len(MIS)\n",
    "num_vertices_MIS = 77\n",
    "test_size_MIS = int(num_edges_MIS/5)\n",
    "\n",
    "# Contains the 5 parts forming the whole dataset\n",
    "parts_MIS = []\n",
    "\n",
    "start = 0\n",
    "end = test_size_MIS\n",
    "for part in range(5):  # We create the 5 parts\n",
    "    if end>num_edges_MIS:\n",
    "        parts_MIS.append(MIS[start:])\n",
    "    else:parts_MIS.append(MIS[start:end])\n",
    "    start = end\n",
    "    end = start + test_size_MIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIS_G = nx.Graph()\n",
    "for edge in range(len(MIS)):\n",
    "    nodes = MIS[edge][0].split(' ')\n",
    "    MIS_G.add_edge(int(nodes[0]), int(nodes[1]), weight=float(nodes[2]))\n",
    "MIS_nodes = MIS_G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs contains the 5 different training networks \n",
    "# targets contains the target links corresponding\n",
    "\n",
    "MIS_graphs = []\n",
    "MIS_targets = []\n",
    "\n",
    "for i in range(5):     # i is the index of the folder we won't use\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(MIS_nodes)\n",
    "    target_links = [] \n",
    "    for j in range(5): # We use every other folder\n",
    "        data = parts_MIS[j]\n",
    "        if j!=i:        \n",
    "            for edge in range(len(data)):\n",
    "                nodes = data[edge][0].split(' ')\n",
    "                G.add_edge(int(nodes[0]), int(nodes[1]), weight=float(nodes[2])) \n",
    "                \n",
    "                \n",
    "        else:\n",
    "            for edge in range(len(data)):\n",
    "                nodes = data[edge][0].split(' ')\n",
    "                # For undirected network, we write the min node first\n",
    "                target_links.append([min(int(nodes[0]),int(nodes[1])),max(int(nodes[0]),int(nodes[1]))])\n",
    "                \n",
    "                \n",
    "\n",
    "    MIS_graphs.append(G)\n",
    "    MIS_targets.append(target_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_MISS_R = CV_random_results(MIS_graphs,MIS_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15298700158840625"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP_MISS_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
